{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfc0f101-c2f9-4090-ae0c-7e2d1a6664be",
   "metadata": {},
   "source": [
    "## Working with NLTK Package ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dd54e3-ec0f-43cf-a6b5-e09004c4803f",
   "metadata": {},
   "source": [
    "Nltk Package is Text Processing and NLP Based Package, it has lot of Models, corpus and other methods which can help you with\n",
    "NLP Applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93da8af-af01-4cfe-9ec1-8bc52e4958b2",
   "metadata": {},
   "source": [
    "you all possible things, like tokenisation and vectorisation, Embeddings, stemming and Lemmatisation...\n",
    "it is easy to use because it donot object oriented technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0be6ba80-1d3f-417b-b3e6-c2dc33110bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dd72d1c-2630-4b17-a803-6e115f63ca95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Imart\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Imart\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86efff9d-9470-4b00-9575-e0d9654518e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ''' Mr. Shahrukh Like the Vadapav of Mumbai. And Mr. Salman Khan Like Chaat of the New Delhi''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d4daffe-e700-4166-9283-56f489d183c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sentences = sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11060a6d-2387-42c7-880e-dccb951dfc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences : [' Mr. Shahrukh Like the Vadapav of Mumbai.', 'And Mr. Salman Khan Like Chaat of the New Delhi']\n"
     ]
    }
   ],
   "source": [
    "print('sentences :',sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a33ab0c-8f20-461f-aab2-c0a68ab63bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mr. Shahrukh Like the Vadapav of Mumbai.\n",
      "And Mr. Salman Khan Like Chaat of the New Delhi\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd5363bc-4308-4ded-9218-7f27d1c3ca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "words = word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de8014db-63e3-4cfc-aa59-b2cade6204fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words ['Mr.', 'Shahrukh', 'Like', 'the', 'Vadapav', 'of', 'Mumbai', '.', 'And', 'Mr.', 'Salman', 'Khan', 'Like', 'Chaat', 'of', 'the', 'New', 'Delhi']\n"
     ]
    }
   ],
   "source": [
    "print('words',words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6a6cc91-9e9f-49c1-b411-ceb07c475f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_words = [word.lower() for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da81b874-2494-4ea6-8d82-29d0981f208f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower case words : ['mr.', 'shahrukh', 'like', 'the', 'vadapav', 'of', 'mumbai', '.', 'and', 'mr.', 'salman', 'khan', 'like', 'chaat', 'of', 'the', 'new', 'delhi']\n"
     ]
    }
   ],
   "source": [
    "print('lower case words :',lower_words) #in spacy package we have to type_cast the word tokeniser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "385fd7c8-fcac-4f3e-bcb9-df9786c13f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = set(lower_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "651f0abf-968f-4bcb-a545-6f2e0c6ef261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabs of unique words {'new', 'like', 'the', 'and', 'mumbai', 'chaat', 'khan', 'delhi', '.', 'salman', 'shahrukh', 'of', 'mr.', 'vadapav'}\n"
     ]
    }
   ],
   "source": [
    "print('vocabs of unique words',vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c13fcb7-ede8-439e-9037-4a5ddc659b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grammer : Rule of the English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "510f78e8-ba7a-4fdf-9c67-e5f380f456f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if we free the vocabs no body can modify it and hence it can at as grammer rule.\n",
    "grammer = frozenset(vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b139c76c-fc85-419a-a1ef-7f52b5ec140e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammer: frozenset({'new', 'like', 'the', 'and', 'mumbai', 'chaat', 'khan', 'delhi', '.', 'salman', 'shahrukh', 'of', 'mr.', 'vadapav'})\n"
     ]
    }
   ],
   "source": [
    "print('Grammer:',grammer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23264441-7a81-42ea-a816-d232e9af3079",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'frozenset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgrammer\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;66;03m# No body can touch it.\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: 'frozenset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(grammer[1]) # No body can touch it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2ca317-a6a5-4595-ad5d-8dc14b27e8c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
